{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e18535-772e-4cd8-9453-77e95645f32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Унікальні класи: [5 4 1 0 2 3]\n",
      "Кількість прикладів по класах:\n",
      " class_6\n",
      "0    505\n",
      "1    489\n",
      "2    310\n",
      "3    193\n",
      "4    603\n",
      "5    260\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Device: cuda | Train samples: 1888 | Val samples: 472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "ROOT_PATH = r\"C:\\Users\\Professional\\PycharmProjects\\pythonProject\"\n",
    "IMAGE_PATH = os.path.join(ROOT_PATH, \"images\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 6\n",
    "EPOCHS = 40\n",
    "IMG_SIZE = 224  # Розмір для ResNet18\n",
    "MODEL_SAVE_PATH = os.path.join(ROOT_PATH, \"resnet18_yoga_finetuned.pth\")\n",
    "\n",
    "# ==========================\n",
    "# DATASET\n",
    "# ==========================\n",
    "class YogaDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None, folder=\"train_images\", has_labels=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.loc[idx, \"image_id\"]\n",
    "        img_path = os.path.join(self.root_dir, self.folder, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Не знайдено зображення: {img_path}\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = int(self.df.loc[idx, \"class_6\"])\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "# ==========================\n",
    "# EVALUATION\n",
    "# ==========================\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = 100 * correct / total if total > 0 else 0\n",
    "    return acc, all_preds, all_labels\n",
    "\n",
    "# ==========================\n",
    "# TRAIN ONE EPOCH\n",
    "# ==========================\n",
    "def train_one_epoch(model, loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total if total > 0 else 0\n",
    "    avg_loss = running_loss / len(loader) if len(loader) > 0 else 0\n",
    "    print(f\"[Epoch {epoch}] Train loss: {avg_loss:.4f} | Train accuracy: {train_acc:.2f}%\")\n",
    "    return train_acc\n",
    "\n",
    "# ==========================\n",
    "# MAIN\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    import multiprocessing\n",
    "    multiprocessing.freeze_support()\n",
    "\n",
    "    # --- Load CSV ---\n",
    "    csv_path = os.path.join(ROOT_PATH, \"train.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Не знайдено {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # --- Перевірка класів ---\n",
    "    print(\"Унікальні класи:\", df[\"class_6\"].unique())\n",
    "    print(\"Кількість прикладів по класах:\\n\", df[\"class_6\"].value_counts().sort_index(), \"\\n\")\n",
    "\n",
    "    # --- Train/Val split ---\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=0.2,\n",
    "        stratify=df[\"class_6\"],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # --- WeightedRandomSampler для балансування ---\n",
    "    counts = train_df[\"class_6\"].value_counts().sort_index().values\n",
    "    inv_counts = 1.0 / counts\n",
    "    sample_weights = train_df[\"class_6\"].map(lambda x: inv_counts[x]).values\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # --- Transforms ---\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(int(IMG_SIZE * 1.14)),  # 256 → центральний кроп 224\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # --- Datasets & Loaders ---\n",
    "    train_dataset = YogaDataset(\n",
    "        df=train_df,\n",
    "        root_dir=IMAGE_PATH,\n",
    "        transform=train_transform,\n",
    "        folder=\"train_images\",\n",
    "        has_labels=True\n",
    "    )\n",
    "    val_dataset = YogaDataset(\n",
    "        df=val_df,\n",
    "        root_dir=IMAGE_PATH,\n",
    "        transform=val_transform,\n",
    "        folder=\"train_images\",\n",
    "        has_labels=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=sampler,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- Завантажуємо ResNet18 pretrained та розморожуємо layer3/4 + fc ---\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    for name, param in model.named_parameters():\n",
    "        if not (name.startswith(\"layer3\") or name.startswith(\"layer4\") or name.startswith(\"fc\")):\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # --- Class weights & Loss & Optimizer & Scheduler ---\n",
    "    class_weights = inv_counts / inv_counts.sum()\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.layer3.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.layer4.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.fc.parameters(),    'lr': 3e-4}\n",
    "    ])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"max\",\n",
    "        factor=0.5,\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "    # --- Перед тренуванням ---\n",
    "    print(f\"Device: {DEVICE} | Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}\\n\")\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "        val_acc, preds, labels = evaluate(model, val_loader)\n",
    "        print(f\"[Epoch {epoch}] Validation Accuracy: {val_acc:.2f}%\\n\")\n",
    "\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"→ Збережено нову BEST модель: Val acc = {best_val_acc:.2f}%\\n\")\n",
    "\n",
    "    print(f\"Навчання завершено. Найкраща валід. точність: {best_val_acc:.2f}%\")\n",
    "\n",
    "    # --- Confusion Matrix після останньої епохи ---\n",
    "    cm = confusion_matrix(labels, preds, labels=list(range(NUM_CLASSES)))\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(labels, preds, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
